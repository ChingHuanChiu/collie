{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Regular usage of collie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/mlframework/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(\"../..\")\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "from collie.core import (\n",
    "    Transformer,\n",
    "    Trainer,\n",
    "    Evaluator,\n",
    "    Pusher,\n",
    "    TrainerPayload,\n",
    "    TransformerPayload,\n",
    "    TunerPayload,\n",
    "    Tuner,\n",
    "    EvaluatorPayload,\n",
    "    PusherPayload,\n",
    "    Orchestrator\n",
    ")\n",
    "\n",
    "from collie import Event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 1000\n",
    "input_dim = 20   \n",
    "num_classes = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPTransformer(Transformer):\n",
    "    def __init__(self) -> None:\n",
    "        description = \"MLP Transformer for generating synthetic data\"\n",
    "        super().__init__(description=description)\n",
    "\n",
    "    def handle(self, event) -> Event:\n",
    "\n",
    "        X = torch.randn(num_samples, input_dim)\n",
    "        y = torch.randint(0, num_classes, (num_samples,))\n",
    "\n",
    "        X_data = pd.DataFrame(X.numpy(), columns=[f\"feature_{i}\" for i in range(input_dim)])\n",
    "        y_data = pd.DataFrame(y.numpy(), columns=[\"label\"])\n",
    "\n",
    "        train_data = pd.concat([X_data, y_data], axis=1)\n",
    "\n",
    "        return Event(\n",
    "            payload=TransformerPayload(\n",
    "                train_data=train_data,\n",
    "                validation_data=None,\n",
    "                test_data=None\n",
    "            )\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPTuner(Tuner):\n",
    "    def __init__(self) -> None:\n",
    "        description = \"MLP Tuner for hyperparameter optimization\"\n",
    "        super().__init__(description=description)\n",
    "\n",
    "    def handle(self, event: Event) -> Event:\n",
    "        # Find the best hyperparameters (dummy example)\n",
    "        hyperparameters = {\n",
    "            \"learning_rate\": 0.001,\n",
    "            \"batch_size\": 32,\n",
    "        }\n",
    "        # Need to pass train, validation, test data to the next stage\n",
    "        return Event(\n",
    "            payload=TunerPayload(\n",
    "                hyperparameters=hyperparameters,\n",
    "                train_data=event.payload.train_data,\n",
    "                validation_data=event.payload.validation_data,\n",
    "                test_data=event.payload.test_data\n",
    "            )\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 64)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(64, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fc1(x))\n",
    "        return self.fc2(x)\n",
    "\n",
    "\n",
    "class MLPTrainer(Trainer):\n",
    "    def __init__(self):\n",
    "\n",
    "        description = \"MLP Trainer for training the model\"\n",
    "        super().__init__(description=description)\n",
    "        self.model = SimpleClassifier()\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        \n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.optimizer = None\n",
    "        self.scheduler = None\n",
    "\n",
    "    def handle(self, event):\n",
    "\n",
    "        learning_rate = event.payload.hyperparameters.get(\"learning_rate\")\n",
    "        batch_size = event.payload.hyperparameters.get(\"batch_size\")\n",
    "        print(f\"learning_rate: {learning_rate}, batch_size: {batch_size}\")\n",
    "        self.optimizer = optim.Adam(self.model.parameters(), lr=learning_rate)\n",
    "        self.scheduler = optim.lr_scheduler.StepLR(self.optimizer, step_size=10, gamma=0.1)\n",
    "        \n",
    "        train_data = event.payload.train_data\n",
    "\n",
    "        X = torch.tensor(train_data.drop(\"label\", axis=1).values, dtype=torch.float32)\n",
    "        y = torch.tensor(train_data[\"label\"].values, dtype=torch.long) \n",
    "\n",
    "        dataset = TensorDataset(X, y)\n",
    "        dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "        epochs = 10\n",
    "        for epoch in range(1, epochs + 1):\n",
    "            self.model.train()\n",
    "            total_loss = 0.0\n",
    "            for xb, yb in dataloader:\n",
    "                xb, yb = xb.to(self.device), yb.to(self.device)\n",
    "                self.optimizer.zero_grad()\n",
    "                logits = self.model(xb)\n",
    "                loss = self.criterion(logits, yb)\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "                total_loss += loss.item()\n",
    "\n",
    "            self.mlflow.log_metric(\"learning rate\", self.scheduler.get_last_lr()[0], step=epoch)\n",
    "            self.mlflow.log_metric(\"loss\", round(total_loss/len(dataloader), 3), step=epoch)\n",
    "            \n",
    "        return Event(\n",
    "            payload=TrainerPayload(\n",
    "                model=self.model,\n",
    "                train_loss=total_loss/len(dataloader),\n",
    "                val_loss=None\n",
    "            )\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from collie.core.enums.ml_models import ModelFlavor\n",
    "\n",
    "class MLPEvaluator(Evaluator):\n",
    "    def __init__(\n",
    "        self,\n",
    "    ) -> None:\n",
    "        description = \"MLP Evaluator for evaluating the model\"\n",
    "        super().__init__(description=description)\n",
    "\n",
    "    def handle(self, event):\n",
    "        from collie.core.enums.ml_models import MLflowModelStage\n",
    "        \n",
    "        experiment_model = event.payload.model\n",
    "        \n",
    "        production_model = self.load_latest_model(\n",
    "            model_name=self.registered_model_name, \n",
    "            stage=MLflowModelStage.PRODUCTION,\n",
    "            flavor=ModelFlavor.PYTORCH\n",
    "        )\n",
    "        print(f\"Production model: {production_model}\")\n",
    "        \n",
    "        validation_data = self._generate_validation_data()\n",
    "        \n",
    "        experiment_accuracy = self._calculate_accuracy(experiment_model, validation_data)\n",
    "        \n",
    "        if production_model is not None:\n",
    "            production_accuracy = 0#self._calculate_accuracy(production_model, validation_data)\n",
    "        else:\n",
    "            production_accuracy = 0\n",
    "        \n",
    "        is_better = experiment_accuracy >= production_accuracy\n",
    "        \n",
    "        return Event(\n",
    "            payload=EvaluatorPayload(\n",
    "                metrics=[\n",
    "                    {\n",
    "                        \"experiment_accuracy\": experiment_accuracy,\n",
    "                        \"production_accuracy\": production_accuracy,\n",
    "                        \"accuracy_improvement\": experiment_accuracy - production_accuracy\n",
    "                    }\n",
    "                ],\n",
    "                is_better_than_production=is_better\n",
    "            )\n",
    "        )\n",
    "    \n",
    "    def _generate_validation_data(self):\n",
    "        torch.manual_seed(42) \n",
    "        \n",
    "        validation_samples = 200\n",
    "        X_val = torch.randn(validation_samples, input_dim)\n",
    "        y_val = torch.randint(0, num_classes, (validation_samples,))\n",
    "        \n",
    "        return {\n",
    "            'features': X_val,\n",
    "            'labels': y_val\n",
    "        }\n",
    "    \n",
    "    def _calculate_accuracy(self, model, validation_data):\n",
    "        model.eval() \n",
    "        \n",
    "        with torch.no_grad():\n",
    "            features = validation_data['features']\n",
    "            labels = validation_data['labels']\n",
    "        \n",
    "            device = next(model.parameters()).device\n",
    "            features = features.to(device)\n",
    "            \n",
    "            outputs = model(features)\n",
    "            probabilities = F.softmax(outputs, dim=1)\n",
    "            predicted_labels = torch.argmax(probabilities, dim=1).cpu().numpy()\n",
    "            \n",
    "            true_labels = labels.numpy()\n",
    "            accuracy = accuracy_score(true_labels, predicted_labels)\n",
    "            \n",
    "            return float(accuracy)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pusher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collie.core.enums.ml_models import MLflowModelStage\n",
    "class MLPPusher(Pusher):\n",
    "    def __init__(self) -> None:\n",
    "        \n",
    "        description = \"MLP Pusher for pushing the model to registry\"\n",
    "        super().__init__(\n",
    "            description=description,\n",
    "            target_stage=MLflowModelStage.PRODUCTION\n",
    "        )\n",
    "\n",
    "    def handle(self, event):\n",
    "        return Event(\n",
    "            payload=PusherPayload(\n",
    "                model_uri=\"mlp_model_uri\",\n",
    "            )\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/14 15:10:49 INFO mlflow.system_metrics.system_metrics_monitor: Skip logging GPU metrics. Set logger level to DEBUG for more details.\n",
      "2025/10/14 15:10:49 INFO mlflow.system_metrics.system_metrics_monitor: Started monitoring system metrics.\n",
      "/opt/anaconda3/envs/mlframework/lib/python3.12/site-packages/mlflow/data/dataset_source_registry.py:148: UserWarning: Failed to determine whether UCVolumeDatasetSource can resolve source information for 'gs://pchome-hadoopincloud-hadoop/user/stevenchiou/mlflow_tmp/1/05376fad3377483db8caa6d2402ad1df/artifacts/train.csv'. Exception: \n",
      "  return _dataset_source_registry.resolve(\n",
      "/opt/anaconda3/envs/mlframework/lib/python3.12/site-packages/mlflow/types/utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n",
      "2025/10/14 15:10:50 INFO mlflow.system_metrics.system_metrics_monitor: Stopping system metrics monitoring...\n",
      "2025/10/14 15:10:50 INFO mlflow.system_metrics.system_metrics_monitor: Successfully terminated system metrics monitoring!\n",
      "2025/10/14 15:10:50 INFO mlflow.system_metrics.system_metrics_monitor: Skip logging GPU metrics. Set logger level to DEBUG for more details.\n",
      "2025/10/14 15:10:50 INFO mlflow.system_metrics.system_metrics_monitor: Started monitoring system metrics.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run Transformer at: http://localhost:5000/#/experiments/1/runs/05376fad3377483db8caa6d2402ad1df\n",
      "üß™ View experiment at: http://localhost:5000/#/experiments/1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/14 15:10:50 INFO mlflow.system_metrics.system_metrics_monitor: Stopping system metrics monitoring...\n",
      "2025/10/14 15:10:50 INFO mlflow.system_metrics.system_metrics_monitor: Successfully terminated system metrics monitoring!\n",
      "2025/10/14 15:10:50 INFO mlflow.system_metrics.system_metrics_monitor: Skip logging GPU metrics. Set logger level to DEBUG for more details.\n",
      "2025/10/14 15:10:50 INFO mlflow.system_metrics.system_metrics_monitor: Started monitoring system metrics.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run Tuner at: http://localhost:5000/#/experiments/1/runs/d08546ce2dc64829966009611ba99653\n",
      "üß™ View experiment at: http://localhost:5000/#/experiments/1\n",
      "learning_rate: 0.001, batch_size: 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/14 15:10:51 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "\u001b[31m2025/10/14 15:10:56 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "2025/10/14 15:10:57 INFO mlflow.system_metrics.system_metrics_monitor: Stopping system metrics monitoring...\n",
      "2025/10/14 15:10:57 INFO mlflow.system_metrics.system_metrics_monitor: Successfully terminated system metrics monitoring!\n",
      "2025/10/14 15:10:57 INFO mlflow.system_metrics.system_metrics_monitor: Skip logging GPU metrics. Set logger level to DEBUG for more details.\n",
      "2025/10/14 15:10:57 INFO mlflow.system_metrics.system_metrics_monitor: Started monitoring system metrics.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run Trainer at: http://localhost:5000/#/experiments/1/runs/123a4f8d345748248a09abe97f1a8b5c\n",
      "üß™ View experiment at: http://localhost:5000/#/experiments/1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/qiujinghuan-31794/Desktop/collie/example/mlp/../../collie/contracts/mlflow.py:138: FutureWarning: ``mlflow.tracking.client.MlflowClient.get_latest_versions`` is deprecated since 2.9.0. Model registry stages will be removed in a future major release. To learn more about the deprecation of model registry stages, see our migration guide here: https://mlflow.org/docs/latest/model-registry.html#migrating-from-stages\n",
      "  latest_versions = self._mlflow_client.get_latest_versions(model_name, stages=[stage])\n",
      "Downloading artifacts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:00<00:00, 21.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Production model: SimpleClassifier(\n",
      "  (fc1): Linear(in_features=20, out_features=64, bias=True)\n",
      "  (relu): ReLU()\n",
      "  (fc2): Linear(in_features=64, out_features=4, bias=True)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Registered model 'MLPClassifier' already exists. Creating a new version of this model...\n",
      "2025/10/14 15:10:59 WARNING mlflow.tracking._model_registry.fluent: Run with id 123a4f8d345748248a09abe97f1a8b5c has no artifacts at artifact path 'model', registering model based on models:/m-bf238df64948410994812a165885795d instead\n",
      "2025/10/14 15:10:59 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: MLPClassifier, version 5\n",
      "Created version '5' of model 'MLPClassifier'.\n",
      "/Users/qiujinghuan-31794/Desktop/collie/example/mlp/../../collie/contracts/mlflow.py:233: FutureWarning: ``mlflow.tracking.client.MlflowClient.get_latest_versions`` is deprecated since 2.9.0. Model registry stages will be removed in a future major release. To learn more about the deprecation of model registry stages, see our migration guide here: https://mlflow.org/docs/latest/model-registry.html#migrating-from-stages\n",
      "  latest_versions = self._mlflow_client.get_latest_versions(model_name, stages=stages)\n",
      "/Users/qiujinghuan-31794/Desktop/collie/example/mlp/../../collie/contracts/mlflow.py:201: FutureWarning: ``mlflow.tracking.client.MlflowClient.transition_model_version_stage`` is deprecated since 2.9.0. Model registry stages will be removed in a future major release. To learn more about the deprecation of model registry stages, see our migration guide here: https://mlflow.org/docs/latest/model-registry.html#migrating-from-stages\n",
      "  self._mlflow_client.transition_model_version_stage(\n",
      "2025/10/14 15:10:59 INFO mlflow.system_metrics.system_metrics_monitor: Stopping system metrics monitoring...\n",
      "2025/10/14 15:10:59 INFO mlflow.system_metrics.system_metrics_monitor: Successfully terminated system metrics monitoring!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run Evaluator at: http://localhost:5000/#/experiments/1/runs/41ebb07e48ab4f67aea03cba2f8d0a8c\n",
      "üß™ View experiment at: http://localhost:5000/#/experiments/1\n",
      "üèÉ View run Pusher at: http://localhost:5000/#/experiments/1/runs/c7bde0369cfa4cc3965b017d7210e302\n",
      "üß™ View experiment at: http://localhost:5000/#/experiments/1\n",
      "üèÉ View run Orchestrator at: http://localhost:5000/#/experiments/1/runs/205e9339e6a9440cad882602985de408\n",
      "üß™ View experiment at: http://localhost:5000/#/experiments/1\n"
     ]
    }
   ],
   "source": [
    "orchestrator = Orchestrator(\n",
    "    tracking_uri=\"http://localhost:5000\",\n",
    "    components=[\n",
    "        MLPTransformer(),\n",
    "        MLPTuner(),\n",
    "        MLPTrainer(),\n",
    "        MLPEvaluator(),\n",
    "        MLPPusher()\n",
    "    ],\n",
    "    mlflow_tags={\"Example\": \"MLP\"},\n",
    "    experiment_name=\"MLP\",\n",
    "    registered_model_name=\"MLPClassifier\"\n",
    ")\n",
    "orchestrator.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlframework",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
